{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xineHCojGOAJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets peft evaluate accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "YF9n8BjPd2cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Datset #  it wonâ€™t ask anything, and you will get all 1000 rows in the dataset object.\n",
        "dataset = load_dataset(\"shawhin/imdb-truncated\", split=\"train\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "F9jNsiZUqkYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Train / Test Split\n",
        "dataset = dataset[\"train\"].train_test_split(\n",
        "    test_size=0.2,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "53KvHp4KrxhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Tokenizer & Base Model\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2\n",
        ")"
      ],
      "metadata": {
        "id": "9tqyuqd4eNeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize AFTER Splitting\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=False\n",
        "    )\n",
        "\n",
        "tokenized_train = train_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "tokenized_test = test_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")"
      ],
      "metadata": {
        "id": "GR83XIYmj1U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=False\n",
        "    )"
      ],
      "metadata": {
        "id": "1nI5D-zLeanC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply tokenization\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")"
      ],
      "metadata": {
        "id": "QOBC_gVTeodx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Padding Token & Data Collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "0PRdgu6Clxgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining evaluation Metrics\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return accuracy_metric.compute(\n",
        "        predictions=predictions,\n",
        "        references=labels\n",
        "    )"
      ],
      "metadata": {
        "id": "3PypaxO5l1ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Base Model ( Before Training) # Set up trainer without Weights & Biases prompts\n",
        "trainer_base = Trainer(\n",
        "    model=model,\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./base_eval\",\n",
        "        per_device_eval_batch_size=4,\n",
        "        report_to=[],  # <-- disables wandb / all other loggers\n",
        "        do_train=False,\n",
        "        do_eval=True,\n",
        "    ),\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Evaluate the base model\n",
        "base_results = trainer_base.evaluate()\n",
        "print(\"Base Model Evaluation:\", base_results)"
      ],
      "metadata": {
        "id": "YYqlmPfvuAxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Example Predictions (Before LoRA)\n",
        "text_list = [\n",
        "    \"I absolutely loved this movie, it was amazing!\",\n",
        "    \"This was the worst film I have ever seen.\"\n",
        "]\n",
        "\n",
        "inputs = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "print(\"Base model predictions:\", predictions.tolist())"
      ],
      "metadata": {
        "id": "obTrVXL2l_cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure LoRA (PEFT)\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_lin\", \"v_lin\"]\n",
        ")"
      ],
      "metadata": {
        "id": "jMh5cXlAm-lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Arguments\n",
        "# My system doesnot support Evaluation_strategy, so we remove it .\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora_distilbert_sentiment\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    report_to=[],   # <-- disables W&B / all other loggers\n",
        "    save_steps=500,\n",
        "    do_eval=True,  # instead of evaluation_strategy\n",
        ")"
      ],
      "metadata": {
        "id": "IdmXcyLyxSQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with LORA\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")                                                       ####### Since we are running in CPU , it takes lots of time , so we use write the code here.\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "#### Evaluate the Fine tune model\n",
        "lora_results = trainer.evaluate()\n",
        "print(\"LoRA Fine-tuned Model Evaluation:\", lora_results)"
      ],
      "metadata": {
        "id": "jxIeEDKv50XQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}